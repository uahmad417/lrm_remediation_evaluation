{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead90c61-6d05-4745-975c-dc61d16e4f3d",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb70618-c260-4633-9e43-1de609305f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain_core langchain_community langchain-huggingface torch accelerate bitsandbytes docarray unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92f463-8c24-46cd-9b32-ca5a098efd6b",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Install the requirements and import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7120a69-f4f9-427c-a109-174941a2ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b74d267-a2ea-48b5-b2d3-cf5df55d918a",
   "metadata": {},
   "source": [
    "## Environment Variables and Constants\n",
    "\n",
    "Set the API keys and environment variables required for running the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33efd142-6c55-40ea-b734-e99f11085006",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# The hugging face cahces is the location\n",
    "# where the models will be downloaded. It is \n",
    "# recommended to set it in a location which has\n",
    "# sufficient storage space\n",
    "\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"\"\n",
    "os.environ[\"HF_HOME\"] = \"\"\n",
    "\n",
    "TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58faceb8-cf6a-4da4-8510-b33d55bdebf9",
   "metadata": {},
   "source": [
    "## Utitlity Functions\n",
    "\n",
    "Utitlity functions to perform different operations like loading data, formatting data etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f6e3b64f-5e00-464c-aca4-8eb52326b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_to_dataframe(file_path: str, header=0, index_col=0, reset_index=False) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the remediation table into a pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "        * file_path (str): The path to the remidations excel file\n",
    "        * header (int): the row to set as header row\n",
    "        * index_col: column ids. provide if there are rows with multi level sub subrows\n",
    "\n",
    "    Returns:\n",
    "        A pandas `DataFrame` object with the loaded data\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_excel(file_path, header=header, index_col=index_col)\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def convert_df_to_json(df: DataFrame) -> json:\n",
    "    \"\"\"\n",
    "    Converts a pandas `DataFrame` to json format\n",
    "\n",
    "    Args:\n",
    "        * df (DataFrame): A panads `DataFrame` object with required data\n",
    "\n",
    "    Returns:\n",
    "        json data\n",
    "    \"\"\"\n",
    "\n",
    "    json_data = df.to_json(orient=\"records\", indent=4)\n",
    "    return json_data\n",
    "\n",
    "def set_prompt(template) -> ChatPromptTemplate:\n",
    "    \"\"\"\n",
    "    Set up the chat prompt to be used with the model\n",
    "\n",
    "    Args:\n",
    "        * template (str): The prompt template to use\n",
    "\n",
    "    Returns:\n",
    "        `ChatPromptTemplate` object\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    return prompt\n",
    "\n",
    "def load_lrm_model_from_hf(model_id) -> ChatHuggingFace:\n",
    "    \"\"\"\n",
    "    Loads lrm model from hugging face to a `ChatHuggingFace` model\n",
    "\n",
    "    Args:\n",
    "        model_id (str): the hugging face url of the model\n",
    "\n",
    "    Returns:\n",
    "        A `ChatHuggingFace` model\n",
    "    \"\"\"\n",
    "\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "\n",
    "    llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"O1-OPEN/OpenO1-LLama-8B-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "        return_full_text=False\n",
    "        ),\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    "    device_map=\"auto\",\n",
    "    )\n",
    "    model = ChatHuggingFace(llm=llm)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93363908-886a-4ecc-ba3f-d314b008aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "remediations_df = load_excel_to_dataframe(\"./data/Remediations.xlsx\", header=2, index_col=[0,1,2,3,4])\n",
    "scenarios_df = load_excel_to_dataframe(\"./data/Scenarios.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9451a557-26e8-409c-a949-e80b013fdbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_json = convert_df_to_json(scenarios_df)\n",
    "remediations_json = convert_df_to_json(remediations_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
