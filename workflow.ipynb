{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead90c61-6d05-4745-975c-dc61d16e4f3d",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb70618-c260-4633-9e43-1de609305f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain_core langchain_community langchain-huggingface torch accelerate bitsandbytes docarray unstructured jq openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b74d267-a2ea-48b5-b2d3-cf5df55d918a",
   "metadata": {},
   "source": [
    "## Environment Variables and Constants\n",
    "\n",
    "Set the API keys and environment variables required for running the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33efd142-6c55-40ea-b734-e99f11085006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/scratch/project_2013047/models\"\n",
    "os.environ[\"HF_HOME\"] = \"/scratch/project_2013047/models\"\n",
    "\n",
    "\n",
    "TEMPLATE = \"\"\"\n",
    "You are an assistant in security risk analysis.\n",
    "You will be provided with risk scenarios that have certain threats and vulnerabilities. For the threats you will also be provided with possible counter measures.\n",
    "You will be provided with a user scenario and based on that you will be provided with context of related scenarios from you retrieval vector store.\n",
    "You will also be provided with possible countermeasures for all similar scenarios.\n",
    "You need to suggest the appropriate counter measure for the user scenario and give a reasoining as to why it is appropriate.\n",
    "Answer the question based only on the following context. If the question does not relate with the context, just reply 'I don't know'\n",
    "\n",
    "User: {user}\n",
    "\n",
    "Scenarios: {scenarios}\n",
    "\n",
    "countermeasures: {countermeasures}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92f463-8c24-46cd-9b32-ca5a098efd6b",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Install the requirements and import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7120a69-f4f9-427c-a109-174941a2ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_huggingface import (ChatHuggingFace, HuggingFaceEmbeddings,\n",
    "                                   HuggingFacePipeline)\n",
    "from langchain_core.documents.base import Document\n",
    "from pandas import DataFrame\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.base import RunnableLambda\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58faceb8-cf6a-4da4-8510-b33d55bdebf9",
   "metadata": {},
   "source": [
    "## Utitlity Functions\n",
    "\n",
    "Utitlity functions to perform different operations like loading data, formatting data etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6e3b64f-5e00-464c-aca4-8eb52326b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_to_dataframe(file_path: str, header=0, index_col=0, reset_index=False, cols: list = None) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the remediation table into a pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "        * file_path (str): The path to the remidations excel file\n",
    "        * header (int): the row to set as header row\n",
    "        * index_col: column ids. provide if there are rows with multi level sub subrows\n",
    "        * cols (list | None): list of renamed column names\n",
    "    Returns:\n",
    "        A pandas `DataFrame` object with the loaded data\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_excel(file_path, header=header, index_col=index_col)\n",
    "    df = df.reset_index()\n",
    "\n",
    "    if cols:\n",
    "        df.columns = cols\n",
    "    return df\n",
    "\n",
    "def convert_df_to_dict(df: DataFrame, save_path=None) -> dict:\n",
    "    \"\"\"\n",
    "    Converts a pandas `DataFrame` to python dictionary format\n",
    "\n",
    "    Args:\n",
    "        * df (DataFrame): A panads `DataFrame` object with required data\n",
    "        * save_path (str): path if want to save the json (dict) data in a file\n",
    "    Returns:\n",
    "        json data\n",
    "    \"\"\"\n",
    "\n",
    "    json_data = df.to_json(orient=\"records\")\n",
    "    dict_data = json.loads(json_data)\n",
    "\n",
    "    if save_path:\n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump(dict_data, f)\n",
    "            \n",
    "    return dict_data\n",
    "\n",
    "def set_prompt(template) -> ChatPromptTemplate:\n",
    "    \"\"\"\n",
    "    Set up the chat prompt to be used with the model\n",
    "\n",
    "    Args:\n",
    "        * template (str): The prompt template to use\n",
    "\n",
    "    Returns:\n",
    "        `ChatPromptTemplate` object\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    return prompt\n",
    "\n",
    "def load_lrm_model_from_hf(model_id) -> ChatHuggingFace:\n",
    "    \"\"\"\n",
    "    Loads lrm model from hugging face to a `ChatHuggingFace` model\n",
    "\n",
    "    Args:\n",
    "        model_id (str): the hugging face url of the model\n",
    "\n",
    "    Returns:\n",
    "        A `ChatHuggingFace` model\n",
    "    \"\"\"\n",
    "\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "\n",
    "    llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=model_id,\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "        return_full_text=False\n",
    "        ),\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    "    device_map=\"auto\",\n",
    "    )\n",
    "    model = ChatHuggingFace(llm=llm)\n",
    "    return model\n",
    "\n",
    "def create_retrievar_from_vector_store(docs: list):\n",
    "    \"\"\"\n",
    "    Create a retrievar from a vector store.\n",
    "    Embeds documnents, stores into a vector store and creates\n",
    "    a retrievar that can be used to retrieve relevant documents.\n",
    "\n",
    "    Args:\n",
    "        docs (list): A list of `Documents` which need to be embeded.\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    embed = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vector_store = DocArrayInMemorySearch.from_documents(docs, embed)\n",
    "    retrievar = vector_store.as_retriever()\n",
    "\n",
    "    return retrievar\n",
    "\n",
    "def remediation_lookup(scenario_docs: list[Document]) -> dict:\n",
    "    \"\"\"\n",
    "    Get the list of remediations knowing the threat and\n",
    "    vulnerability\n",
    "    The method performs a lookup to get possible countermeasures\n",
    "    to provided threat and vulnerability.\n",
    "\n",
    "    Args:\n",
    "\n",
    "    Returns:\n",
    "        dictionary of possible countermeasures\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: handle NoneType\n",
    "    # TODO: handle leading spaces in doc.page_content\n",
    "    countermeasures = []\n",
    "\n",
    "    for doc in scenario_docs:\n",
    "        \n",
    "        scen_dict = json.loads(doc.page_content)\n",
    "        if scen_dict[\"risk_id\"] is None:\n",
    "            continue\n",
    "        threat_id = scen_dict[\"risk_id\"].strip()\n",
    "        vuln_id = scen_dict[\"vuln_id\"].strip()\n",
    "        x = remediations_df[remediations_df[\"threat_id\"]==threat_id]\n",
    "        df = x[x[\"vuln_id\"]==vuln_id]\n",
    "        \n",
    "        countermeasures.extend(convert_df_to_dict(df))\n",
    "    \n",
    "    return countermeasures\n",
    "\n",
    "def setup_rag_chain(model_id, template):\n",
    "    \"\"\"\n",
    "    create the rag chain\n",
    "    \"\"\"\n",
    "    \n",
    "    scenarios_df = load_excel_to_dataframe(\"./data/Scenarios.xlsx\", cols=[\"scen_id\", \"scen\", \"extended\", \"short\", \"details\", \"risk_id\", \"risk_desc\", \"vuln_id\", \"vuln_desc\", \"risk_occud_type\"])\n",
    "    scenarios_dict = convert_df_to_dict(scenarios_df, save_path=\"./data/scen.json\")\n",
    "    loader_scen = JSONLoader(file_path=\"./data/scen.json\",jq_schema='.[]', text_content=False)\n",
    "    scenarios_doc = loader_scen.load()\n",
    "    scenarios = create_retrievar_from_vector_store(scenarios_doc)\n",
    "\n",
    "    prompt = set_prompt(template)\n",
    "    \n",
    "    model = load_lrm_model_from_hf(model_id=model_id)\n",
    "\n",
    "    output_parser = StrOutputParser()\n",
    "\n",
    "    chain = (\n",
    "        {\n",
    "            \"user\": RunnablePassthrough(),\n",
    "            \"scenarios\": scenarios,\n",
    "            \"countermeasures\": scenarios | RunnableLambda(remediation_lookup),\n",
    "        } \n",
    "        | prompt\n",
    "        | model\n",
    "        | output_parser\n",
    "        \n",
    "    )\n",
    "\n",
    "    return chain\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975646f-3cdc-4949-909a-6c7a82ed97aa",
   "metadata": {},
   "source": [
    "## RAG Workflow\n",
    "\n",
    "This is where the RAG workflow starts from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31da48-246f-4d78-b04e-ac343cd10dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load excel docs\n",
    "remediations_df = load_excel_to_dataframe(\"./data/Remediations.xlsx\", header=2, index_col=[0,1,2,3,4], cols=[\"threat_id\", \"threat_desc\", \"vuln_id\", \"vuln_desc\", \"vthe\", \"remediation_id\", \"remediation_desc\", \"tech_nature\"])\n",
    "# remediations_df = pd.read_excel(\"./data/Remediations.xlsx\", header=2, index_col=[0,1,2,3,4])\n",
    "\n",
    "# TODO: fix this issue where some values event after \n",
    "# resetting the index are NaN\n",
    "for i in range(1360, 1419):\n",
    "    remediations_df.loc[i, \"threat_id\"] = \"M26\"\n",
    "scenarios_df = load_excel_to_dataframe(\"./data/Scenarios.xlsx\", cols=[\"scen_id\", \"scen\", \"extended\", \"short\", \"details\", \"risk_id\", \"risk_desc\", \"vuln_id\", \"vuln_desc\", \"risk_occud_type\"])\n",
    "\n",
    "# # convert dataframe to json\n",
    "# # TODO: strip spaces from cells i.e risk_id = ' M3'\n",
    "scenarios_dict = convert_df_to_dict(scenarios_df, save_path=\"./data/scen.json\")\n",
    "# remediations_dict = convert_df_to_dict(remediations_df, save_path=\"./data/rem.json\")\n",
    "\n",
    "# # convert json data to lanchain Document format\n",
    "loader_scen = JSONLoader(file_path=\"./data/scen.json\",jq_schema='.[]', text_content=False)\n",
    "# loader_rem = JSONLoader(file_path=\"./data/rem.json\",jq_schema='.[]', text_content=False)\n",
    "\n",
    "scenarios_doc = loader_scen.load()\n",
    "# remediations_doc = loader_rem.load()\n",
    "\n",
    "# # save the Documents to the vector store and get\n",
    "# # the retrievar\n",
    "scenarios = create_retrievar_from_vector_store(scenarios_doc)\n",
    "# remediations = create_retrievar_from_vector_store(remediations_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6d6fe-4bea-4eb4-af6f-3672750dde56",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = setup_rag_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d83b7-7814-4983-9c22-5c693fa9758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = setup_rag_chain(model_id=\"O1-OPEN/OpenO1-LLama-8B-v0.1\", template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b865f-782e-4875-b847-464c4341ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = chain.invoke(\"Only authorized users can open the cabinets containing classified documents and no tracking is required.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd5472-d1a4-497e-a4d0-170b11b55319",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
