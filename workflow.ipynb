{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead90c61-6d05-4745-975c-dc61d16e4f3d",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb70618-c260-4633-9e43-1de609305f60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain_core langchain_community langchain-huggingface torch accelerate bitsandbytes docarray unstructured jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92f463-8c24-46cd-9b32-ca5a098efd6b",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Install the requirements and import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b7120a69-f4f9-427c-a109-174941a2ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import JSONLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b74d267-a2ea-48b5-b2d3-cf5df55d918a",
   "metadata": {},
   "source": [
    "## Environment Variables and Constants\n",
    "\n",
    "Set the API keys and environment variables required for running the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33efd142-6c55-40ea-b734-e99f11085006",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# The hugging face cahces is the location\n",
    "# where the models will be downloaded. It is \n",
    "# recommended to set it in a location which has\n",
    "# sufficient storage space\n",
    "\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"\"\n",
    "os.environ[\"HF_HOME\"] = \"\"\n",
    "\n",
    "TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58faceb8-cf6a-4da4-8510-b33d55bdebf9",
   "metadata": {},
   "source": [
    "## Utitlity Functions\n",
    "\n",
    "Utitlity functions to perform different operations like loading data, formatting data etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6e3b64f-5e00-464c-aca4-8eb52326b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_to_dataframe(file_path: str, header=0, index_col=0, reset_index=False) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the remediation table into a pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "        * file_path (str): The path to the remidations excel file\n",
    "        * header (int): the row to set as header row\n",
    "        * index_col: column ids. provide if there are rows with multi level sub subrows\n",
    "\n",
    "    Returns:\n",
    "        A pandas `DataFrame` object with the loaded data\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_excel(file_path, header=header, index_col=index_col)\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def convert_df_to_json(df: DataFrame, save_path=None) -> json:\n",
    "    \"\"\"\n",
    "    Converts a pandas `DataFrame` to json format\n",
    "\n",
    "    Args:\n",
    "        * df (DataFrame): A panads `DataFrame` object with required data\n",
    "        * save_path (str): path if want to save the json data in a file\n",
    "    Returns:\n",
    "        json data\n",
    "    \"\"\"\n",
    "\n",
    "    json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "    if save_path:\n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump(json_data, f)\n",
    "            \n",
    "    return json_data\n",
    "\n",
    "def set_prompt(template) -> ChatPromptTemplate:\n",
    "    \"\"\"\n",
    "    Set up the chat prompt to be used with the model\n",
    "\n",
    "    Args:\n",
    "        * template (str): The prompt template to use\n",
    "\n",
    "    Returns:\n",
    "        `ChatPromptTemplate` object\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    return prompt\n",
    "\n",
    "def load_lrm_model_from_hf(model_id) -> ChatHuggingFace:\n",
    "    \"\"\"\n",
    "    Loads lrm model from hugging face to a `ChatHuggingFace` model\n",
    "\n",
    "    Args:\n",
    "        model_id (str): the hugging face url of the model\n",
    "\n",
    "    Returns:\n",
    "        A `ChatHuggingFace` model\n",
    "    \"\"\"\n",
    "\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "\n",
    "    llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"O1-OPEN/OpenO1-LLama-8B-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "        return_full_text=False\n",
    "        ),\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    "    device_map=\"auto\",\n",
    "    )\n",
    "    model = ChatHuggingFace(llm=llm)\n",
    "    return model\n",
    "\n",
    "def create_retrievar_from_vector_store(docs: list):\n",
    "    \"\"\"\n",
    "    Create a retrievar from a vector store.\n",
    "    Embeds documnents, stores into a vector store and creates\n",
    "    a retrievar that can be used to retrieve relevant documents.\n",
    "\n",
    "    Args:\n",
    "        docs (list): A list of `Documents` which need to be embeded.\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    embed = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vector_store = DocArrayInMemorySearch.from_documents(docs, embed)\n",
    "    retrievar = vector_store.as_retriever()\n",
    "\n",
    "    return retrievar\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975646f-3cdc-4949-909a-6c7a82ed97aa",
   "metadata": {},
   "source": [
    "## RAG Workflow\n",
    "\n",
    "This is where the RAG workflow starts from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd31da48-246f-4d78-b04e-ac343cd10dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load excel docs\n",
    "remediations_df = load_excel_to_dataframe(\"./data/Remediations.xlsx\", header=2, index_col=[0,1,2,3,4])\n",
    "scenarios_df = load_excel_to_dataframe(\"./data/Scenarios.xlsx\")\n",
    "\n",
    "# convert dataframe to json\n",
    "scenarios_json = convert_df_to_json(scenarios_df, save_path=\"./data/scen.json\")\n",
    "remediations_json = convert_df_to_json(remediations_df, save_path=\"./data/rem.json\")\n",
    "\n",
    "# convert json data to lanchain Document format\n",
    "loader_scen = JSONLoader(file_path=\"./data/scen.json\",jq_schema='.')\n",
    "loader_rem = JSONLoader(file_path=\"./data/rem.json\",jq_schema='.')\n",
    "\n",
    "scenarios_doc = loader_scen.load()\n",
    "remediations_doc = loader_rem.load()\n",
    "\n",
    "# save the Documents to the vector store and get\n",
    "# the retrievar\n",
    "scenarios = create_retrievar_from_vector_store(scenarios_doc)\n",
    "remediations = create_retrievar_from_vector_store(remediations_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b0b36af5-94f3-4d58-aea4-09ddc70720f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the prompt\n",
    "prompt = set_prompt(TEMPLATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58038f52-8948-46a4-a4aa-96673879652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
